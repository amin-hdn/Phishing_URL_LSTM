{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from math import log\n",
    "from re import compile\n",
    "from urllib.parse import urlparse\n",
    "from socket import gethostbyname\n",
    "from requests import get\n",
    "from string import ascii_lowercase\n",
    "from numpy import array\n",
    "import time\n",
    "from datetime import datetime\n",
    "from re import compile\n",
    "from json import dump, loads\n",
    "from time import sleep"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature extract our URL :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_entropy(URL):\n",
    "    URL = URL.lower()\n",
    "    probs = [URL.count(c) / len(URL) for c in set(URL)]\n",
    "    entropy = -sum([p * log(p) / log(2.0) for p in probs])\n",
    "    return entropy\n",
    "\n",
    "def url_has_port_in_string(URL_parsed):\n",
    "    try :\n",
    "        has_port = URL_parsed.netloc.split(':')\n",
    "        return 1 if len(has_port) > 1 and has_port[-1].isdigit() else 0\n",
    "    except :\n",
    "        return 0\n",
    "\n",
    "def number_of_digits(URL):\n",
    "    try :\n",
    "        digits = [i for i in URL if i.isdigit()]\n",
    "        return len(digits)\n",
    "    except :\n",
    "        return 0\n",
    "\n",
    "def number_of_parameters(URL_parsed):\n",
    "    try :\n",
    "        params = URL_parsed.query\n",
    "        return 0 if params == '' else len(params.split('&'))\n",
    "    except :\n",
    "        return 0\n",
    "\n",
    "\n",
    "def number_of_fragments(URL_parsed):\n",
    "    try :\n",
    "        frags = URL_parsed.fragment\n",
    "        return frags.count('#') if frags != '' else 0\n",
    "    except :\n",
    "        return 0\n",
    "\n",
    "\n",
    "def is_encoded(URL):\n",
    "    try:\n",
    "        return 1 if '%' in URL else 0\n",
    "    except :\n",
    "        return 0\n",
    "\n",
    "\n",
    "\n",
    "def number_of_dots(URL):\n",
    "    try :\n",
    "        dots = [i for i in URL if i == '.'] ## ??\n",
    "        return len(dots)\n",
    "    except :\n",
    "        return 0\n",
    "\n",
    "def has_client_in_string(URL):\n",
    "    try :\n",
    "        return 1 if 'client' in URL.lower() else 0\n",
    "    except :\n",
    "        return 0\n",
    "\n",
    "def has_admin_in_string(URL):\n",
    "    try :\n",
    "        return 1 if 'admin' in URL.lower() else 0\n",
    "    except :\n",
    "        return 0\n",
    "\n",
    "def has_server_in_string(URL):\n",
    "    try :\n",
    "       return 1 if 'server' in URL.lower() else 0\n",
    "    except :\n",
    "        return 0\n",
    "\n",
    "def has_login_in_string(URL):\n",
    "    try :\n",
    "         return 1 if 'login' in URL.lower() else 0\n",
    "    except :\n",
    "        return 0\n",
    "\n",
    "def get_tld(URL_parsed): # https://miro.medium.com/v2/resize:fi\n",
    "                                             #----\n",
    "    try :\n",
    "        if not url_host_is_ip(URL_parsed) :\n",
    "            tld = URL_parsed.netloc.split('.')[-1].split(':')[0]\n",
    "            return tld if len(tld)<10 else ''\n",
    "        else: return ''\n",
    "    except :\n",
    "        return ''\n",
    "    \n",
    "def url_host_is_ip(URL_parsed):\n",
    "    try :\n",
    "        host = URL_parsed.netloc\n",
    "        pattern = compile(\"^\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}$\")\n",
    "        match = pattern.match(host)\n",
    "        return 1 if match is not None else 0\n",
    "    except :\n",
    "        return 0\n",
    "\n",
    "def CharacterContinuityRate(URL_parsed):\n",
    "    try :\n",
    "\n",
    "        if not url_host_is_ip(URL_parsed):\n",
    "            Domain = URL_parsed.geturl()\n",
    "            counter = dict()\n",
    "            counter['digit'] = 0\n",
    "            counter['alpha'] = 0\n",
    "            counter['symbol'] = 0\n",
    "            counter_digit__ = 0\n",
    "            counter_alpha__ = 0\n",
    "            counter_symbol__ = 0\n",
    "            was_alpha = False\n",
    "            was_digit = False\n",
    "            was_symbol = False\n",
    "            for c in Domain :\n",
    "                if c.isdigit() :\n",
    "                    if was_digit :\n",
    "                        counter_digit__ +=1\n",
    "                    else : \n",
    "                        was_alpha, was_symbol, was_digit = False ,False, True\n",
    "                        counter_digit__  = 1\n",
    "                    counter['digit']= max(counter['digit'], counter_digit__)\n",
    "\n",
    "\n",
    "                elif c.isalpha() :\n",
    "                    if was_alpha :\n",
    "                        counter_alpha__ +=1\n",
    "                    else : \n",
    "                        was_digit, was_symbol, was_alpha = False ,False, True\n",
    "                        counter_alpha__  = 1\n",
    "                    counter['alpha']= max(counter['alpha'], counter_alpha__)\n",
    "                else  :                  \n",
    "                    if was_symbol : \n",
    "                        counter_symbol__ +=1\n",
    "                    else : \n",
    "                        was_digit, was_alpha, was_symbol = False ,False, True\n",
    "                        counter_symbol__  = 1\n",
    "                    counter['symbol']= max(counter['symbol'], counter_symbol__)\n",
    "            return (counter['alpha']+ counter['digit']+ counter['symbol'])/len(Domain)\n",
    "        else :\n",
    "            return 4/15\n",
    "    except :\n",
    "        return 0\n",
    "    \n",
    "\n",
    "def domain_token_count(URL):\n",
    "    try:\n",
    "        token_count= URL.count('/')\n",
    "        return token_count\n",
    "    except :\n",
    "        return 0\n",
    "\n",
    "def Path_Domain_ratio(URL_parsed):\n",
    "    try :\n",
    "        path_ = len(URL_parsed.path)\n",
    "        domain_ = len(URL_parsed.netloc)\n",
    "        return path_ / domain_\n",
    "    except :\n",
    "        return 0\n",
    "\n",
    "\n",
    "def Path_URL_ratio(URL_parsed):\n",
    "        try :\n",
    "            path_ = len(URL_parsed.path)\n",
    "            URL_ = len(URL_parsed.geturl())\n",
    "            return path_ / URL_\n",
    "        except :\n",
    "            return 0\n",
    "\n",
    "\n",
    "def  Query_Digit_Count(URL_parsed):# Number of digits in the query part of the URL.\n",
    "    try :\n",
    "        digits = [i for i in URL_parsed.query if i.isdigit()]\n",
    "        return len(digits)\n",
    "    except :\n",
    "        return 0\n",
    "\n",
    "def Longest_Path_token(URL_parsed):\n",
    "    try :\n",
    "        Path_ = URL_parsed.path\n",
    "        lengths_ = list()\n",
    "        counter = 0\n",
    "        for c in Path_ :\n",
    "            if c == '/': \n",
    "                lengths_.append(counter)\n",
    "                counter = 0\n",
    "            else: counter += 1\n",
    "\n",
    "        return max(lengths_)\n",
    "    except :\n",
    "        return 0\n",
    "\n",
    "def Symbol_Count_Domain(URL):  #in \"://.:/?=,;()]+\"\n",
    "    try :\n",
    "        counter = 0  \n",
    "        for c in URL:\n",
    "            if c in \"://.:/?=,;()]+\" : counter += 1\n",
    "        return counter\n",
    "    except :\n",
    "        return 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __get_ip(URL_parsed):\n",
    "    try:\n",
    "        ip = URL_parsed.netloc if url_host_is_ip(URL_parsed) else gethostbyname(URL_parsed.netloc)\n",
    "        return ip\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "\t\n",
    "def URL_scheme(URL_parse):\n",
    "    try :\n",
    "        scheme = URL_parse.scheme\n",
    "        return scheme\n",
    "    except :\n",
    "        return ''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import validators.url as url\n",
    "\n",
    "\n",
    "def URLParse_with_exeption(URL):\n",
    "    try :\n",
    "        url_parse = urlparse(URL)\n",
    "        return url_parse\n",
    "    except ValueError :\n",
    "        print(URL)\n",
    "        return None\n",
    "def validate_url(URL):\n",
    "    if not url(URL):\n",
    "        URL = \"NoScheme://\" + URL\n",
    "    return URL\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'joblib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39m# import category_encoders as ce\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m my_encoder \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mEncoder_BDE.gz\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m my_scaler \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mStandardScaler.gz\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m my_PCA \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mPCA.gz\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'joblib' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import category_encoders as ce\n",
    "URL = input('URL...................\\n')\n",
    "One_URL_df = pd.DataFrame( data=[ URL] , columns=[ 'url'])\n",
    "One_URL_df.head()\n",
    "\n",
    "my_encoder = joblib.load('Encoder_BDE.gz')\n",
    "my_scaler = joblib.load('StandardScaler.gz')\n",
    "my_PCA = joblib.load('PCA.gz')\n",
    "my_LSTM_model = joblib.load('LSTM_model.gz')\n",
    "\n",
    "\n",
    "############################ lecixal features #############################################\n",
    "\n",
    "One_URL_df[\"entropy\"] = One_URL_df[\"url\"].apply(get_entropy)\n",
    "One_URL_df[\"url_parsed\"] = One_URL_df[\"url\"].apply(validate_url).apply(URLParse_with_exeption)\n",
    "One_URL_df[\"has_a_port\"] = One_URL_df[\"url_parsed\"].apply(url_has_port_in_string)\n",
    "One_URL_df[\"number_of_digits\"] = One_URL_df[\"url\"].apply(number_of_digits)\n",
    "One_URL_df[\"number_of_parameters\"] = One_URL_df[\"url_parsed\"].apply(number_of_parameters)\n",
    "One_URL_df[\"number_of_fragments\"] = One_URL_df[\"url_parsed\"].apply(number_of_fragments)\n",
    "One_URL_df['URL_host_is_IP'] = One_URL_df['url_parsed'].apply(url_host_is_ip)\n",
    "One_URL_df[\"is_encoded\"] = One_URL_df[\"url\"].apply(is_encoded)\n",
    "One_URL_df[\"has_client\"] = One_URL_df[\"url\"].apply(has_client_in_string)\n",
    "One_URL_df[\"has_admin\"] = One_URL_df[\"url\"].apply(has_admin_in_string)\n",
    "One_URL_df[\"has_server\"] = One_URL_df[\"url\"].apply(has_server_in_string)\n",
    "One_URL_df[\"has_login\"] = One_URL_df[\"url\"].apply(has_login_in_string)\n",
    "One_URL_df[\"number_of_dots\"] = One_URL_df[\"url\"].apply(number_of_dots)\n",
    "One_URL_df[\"CCR\"] = One_URL_df[\"url_parsed\"].apply(CharacterContinuityRate)\n",
    "One_URL_df[\"Symbol_Count_Domain\"] = One_URL_df[\"url\"].apply(Symbol_Count_Domain)\n",
    "One_URL_df[\"Longest_Path_token\"] = One_URL_df[\"url_parsed\"].apply(Longest_Path_token)\n",
    "One_URL_df[\"Query_Digit_Count\"] = One_URL_df[\"url_parsed\"].apply(Query_Digit_Count)\n",
    "One_URL_df[\"Path_URL_ratio\"] = One_URL_df[\"url_parsed\"].apply(Path_URL_ratio)\n",
    "One_URL_df[\"Path_Domain_ratio\"] = One_URL_df[\"url_parsed\"].apply(Path_Domain_ratio)\n",
    "One_URL_df[\"domain_token_count\"] = One_URL_df[\"url\"].apply(domain_token_count)\n",
    "\n",
    "############################ Host_Based features #############################################\n",
    "\n",
    "One_URL_df[\"tld\"] = One_URL_df[\"url_parsed\"].apply(get_tld)\n",
    "One_URL_df[\"URL_scheme\"] = One_URL_df[\"url_parsed\"].apply(URL_scheme)\n",
    "\n",
    "###### encoding #######\n",
    "\n",
    "One_URL_df = One_URL_df.drop(columns=('url_parsed'),)\n",
    "\n",
    "obj_df = One_URL_df.select_dtypes(include=['object'])\n",
    "df_bd = my_encoder.transform(One_URL_df)\n",
    "One_URL_df_bd = df_bd.iloc[:,1:]\n",
    "\n",
    "###### scaling #######\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "numeric_df = One_URL_df_bd.select_dtypes(include=['int16', 'int32', 'int64', 'float16', 'float32', 'float64'])\n",
    "numeric_values = numeric_df.values\n",
    "numeric_values = my_scaler.transform(numeric_df.to_numpy())\n",
    "scaled_numeric_df = pd.DataFrame(data = numeric_values\n",
    "             , columns = numeric_df.columns )\n",
    "###### PCA ############\n",
    "\n",
    "\n",
    "Principal_C = my_PCA.transform(scaled_numeric_df)\n",
    "\n",
    "k = my_PCA.n_components_\n",
    "\n",
    "principalDf = pd.DataFrame(data = Principal_C\n",
    "             , columns = ['Principal_C'+str(i) for i in range(1,k+1)])\n",
    "principalDf.head()\n",
    "\n",
    "###### the last result ########\n",
    "result = One_URL_df_bd.drop(numeric_df.columns, axis=1)\n",
    "New_on_URL_DF =  result.join( principalDf,) \n",
    "New_on_URL_DF.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "X = New_on_URL_DF.iloc[:,[i for i in range(1,35)] ].values\n",
    "X = X.reshape(34,1)\n",
    "predicted_class=my_LSTM_model.predict(tf.expand_dims(X,0)).argmax()\n",
    "print(predicted_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
